# app/services/text_chat.py (ì˜ˆì‹œ íŒŒì¼ëª…)
from __future__ import annotations  # ì„ íƒ: ìˆìœ¼ë©´ íƒ€ì… í‰ê°€ ì§€ì—°ë˜ì–´ ë” ì•ˆì „
from ..services.llm_client import get_model
from app.util.roleplay_text_chain import create_initial_prompt, create_roleplay_chain
import re
# app/services/voicechat_service.py
# íŒŒì¼ ë§¨ ìœ„ìª½
from typing import Any, Dict, List, Optional, Tuple


__all__ = ["run_chat_pipeline"]

def run_chat_pipeline(audio_bytes: bytes, topic: str, ai_role: str, user_role: str) -> Dict[str, Any]:
    """
    STT -> LLM -> TTSê¹Œì§€ í•œ ë²ˆì— ì²˜ë¦¬.
    ë°˜í™˜ ì˜ˆì‹œ:
      {
        "user_text": "...",
        "ai_text": "...",
        "tts_path": "C:/.../out.wav"  # ë˜ëŠ” bytes
      }
    """
    # ğŸ” ìˆœí™˜ ì„í¬íŠ¸ ë°©ì§€ìš© ì§€ì—° ì„í¬íŠ¸
    from ..services.stt_google import transcribe_bytes
    from ..services.tts_google import synth_to_file  # synth_to_wav_bytes ì“°ë©´ ê·¸ê±¸ë¡œ êµì²´
    from ..util.roleplay_chain import create_initial_prompt, create_roleplay_chain

    # 1) ìŒì„± â†’ í…ìŠ¤íŠ¸
    user_text = transcribe_bytes(audio_bytes) or ""

    # 2) LLM ì‘ë‹µ ìƒì„±
    #    (ë„¤ ì²´ì¸ ì‹œê·¸ë‹ˆì²˜ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”)
    chain = create_roleplay_chain()
    # ì˜ˆì‹œ ì…ë ¥ í‚¤: topic, ai_role, user_role, user_message
    result = chain.invoke({
        "topic": topic,
        "ai_role": ai_role,
        "user_role": user_role,
        "user_message": user_text
    })
    # ì²´ì¸ ì¶œë ¥ í˜•íƒœì— ë§ê²Œ íŒŒì‹± (ì—¬ê¸°ì„  ì˜ˆì‹œë¡œ 'ai_reply' í‚¤ë¥¼ ê°€ì •)
    ai_text = result.get("ai_reply") if isinstance(result, dict) else str(result)

    # 3) í…ìŠ¤íŠ¸ â†’ ìŒì„± íŒŒì¼
    #    synth_to_file(text, out_path) ê°™ì€ ì‹œê·¸ë‹ˆì²˜ë¼ ê°€ì •. ë‹¤ë¥´ë©´ ë§ì¶° ìˆ˜ì •.
    tts_path = synth_to_file(ai_text)  # ê²½ë¡œ ë¦¬í„´í•˜ë„ë¡ êµ¬í˜„ë¼ ìˆì–´ì•¼ í•¨

    return {
        "user_text": user_text,
        "ai_text": ai_text,
        "tts_path": tts_path,
    }

# ---------------------------------------------
# ìœ í‹¸
# ---------------------------------------------
_POS_KW = ['ì™„ë²½', 'ìì—°', 'ì¢‹', 'ì ì ˆ', 'ë¬¸ì œ ì—†ìŒ', 'ê´œì°®', 'ì •í™•', 'ì˜¬ë°”ë¥´']
_NEG_KW = ['ì–´ìƒ‰', 'ë¶€ìì—°', 'ìˆ˜ì •', 'ê°œì„ ', 'ë¬¸ì œ', 'ì• ë§¤', 'ë¶ˆë¶„ëª…', 'ì˜¤ë¥˜', 'í‹€ë¦¼']

def _normalize_feedback_format(text: str) -> str:
    if not isinstance(text, str):
        return ""
    text = re.sub(r'\bSuggestion\b\s*[:\-]', 'suggestion:', text, flags=re.I)
    text = re.sub(r'\bGrammar\b\s*[:\-]', 'grammar:', text, flags=re.I)
    text = re.sub(r'\bVocabulary\b\s*[:\-]', 'vocabulary:', text, flags=re.I)
    text = re.sub(r'(\S)\n{0,1}suggestion:', r'\1\n\nsuggestion:', text)
    return text

def _polarity(text: str) -> int:
    t = text.lower()
    pos = any(k in t for k in _POS_KW)
    neg = any(k in t for k in _NEG_KW)
    if pos and not neg: return 1
    if neg and not pos: return -1
    return 0

def _candidate_lines_from_suggestion(sugg: str) -> List[str]:
    lines = []
    for ln in sugg.splitlines():
        ln = ln.strip()
        if not ln: continue
        ln = re.sub(r'^\d+\.\s*', '', ln)
        ln = re.sub(r'^(hi|hello|hey)[!,.]?\s*', '', ln, flags=re.I)
        lines.append(ln)
    lines.sort(key=lambda s: abs(len(s.split()) - 9))
    return lines

def _tokenize(s: str) -> List[str]:
    return re.findall(r'\b[a-z]+\b', s.lower())

def _extract_sections(ai_output: str):
    """grammar / vocabulary / suggestion ë¶„ë¦¬ ì¶”ì¶œ"""
    gram = re.search(
        r'(?i)grammar\s*[:\-]\s*([\s\S]*?)(?=\n\s*vocabulary\s*[:\-]|\n\s*suggestion\s*[:\-]|$)',
        ai_output
    )
    voca = re.search(
        r'(?i)vocabulary\s*[:\-]\s*([\s\S]*?)(?=\n\s*suggestion\s*[:\-]|$)',
        ai_output
    )
    sugg = re.search(r'(?i)suggestion\s*[:\-]\s*([\s\S]*)', ai_output)
    g_txt = gram.group(1).strip() if gram else ''
    v_txt = voca.group(1).strip() if voca else ''
    s_txt = sugg.group(1).strip() if sugg else ''
    return g_txt, v_txt, s_txt

def _categories_from_sections(g_txt: str, v_txt: str) -> List[str]:
    cats: List[str] = []
    if _polarity(g_txt) == -1: cats.append('GRAMMAR')
    if _polarity(v_txt) == -1: cats.append('VOCABULARY')
    return cats

def calculate_similarity_score(user_message: str, ai_output: str) -> int:
    ai_output = _normalize_feedback_format(ai_output or "")
    _, _, suggestion_text = _extract_sections(ai_output)

    uw = set(_tokenize(user_message or ""))
    best = 0.0
    if uw and suggestion_text:
        for cand in _candidate_lines_from_suggestion(suggestion_text):
            sw = set(_tokenize(cand))
            if not sw: continue
            inter = len(uw & sw); union = len(uw | sw)
            j = inter / union if union else 0.0
            best = max(best, j)

    score = int(round(best * 100))
    g_txt, v_txt, _ = _extract_sections(ai_output)
    g_pol = _polarity(g_txt); v_pol = _polarity(v_txt)

    if g_pol == 1 and v_pol == 1:
        score = max(score, 90)
        if not suggestion_text or re.search(r'(no\s+change|looks\s+good|fine|perfect)', suggestion_text, re.I):
            score = max(score, 95)
    elif g_pol == -1 or v_pol == -1:
        score = min(score, 60)
    else:
        if not suggestion_text:
            score = max(score, 75 if uw else 50)

    return max(15, min(100, score))

def _level_by_score(score: int) -> str:
    # ë°±ì—”ë“œ ë³´ê´€ìš©(ë¬¸ìì—´): 'excellent' | 'good' | 'needs-work'
    if score >= 90: return 'excellent'
    if score >= 75: return 'good'
    return 'needs-work'

# ---------------------------------------------
# ì´ˆê¸° ì¸ì‚¬
# ---------------------------------------------
async def start_chat_service(data: Dict):
    topic = data.get("topic", "hospital")
    ai_role = data.get("ai_role", "doctor")
    user_role = data.get("user_role", "patient")
    prompt = create_initial_prompt(topic, ai_role, user_role)
    model = get_model()
    response = model.invoke(prompt)
    reply = _normalize_feedback_format(getattr(response, "content", str(response)))
    return {"reply": reply}

# ---------------------------------------------
# ì‚¬ìš©ì ë©”ì‹œì§€ ì „ì†¡ + ì ìˆ˜/ì¹´í…Œê³ ë¦¬/ì„¹ì…˜ ë°˜í™˜
# ---------------------------------------------
async def send_message_service(data: Dict):
    topic = data.get("topic")
    ai_role = data.get("ai_role")
    user_role = data.get("user_role")
    user_message = data.get("message", "")

    chain = create_roleplay_chain()
    result = chain.invoke({
        "topic": topic, "ai_role": ai_role, "user_role": user_role,
        "user_message": user_message
    })

    reply_text = getattr(result, "content", str(result))
    reply_text = _normalize_feedback_format(reply_text)

    score = calculate_similarity_score(user_message, reply_text)
    level = _level_by_score(score)

    g_txt, v_txt, s_txt = _extract_sections(reply_text)
    categories = _categories_from_sections(g_txt, v_txt)

    # [AI Reply]/[Feedback] í¬ë§·ì€ ìœ ì§€(í”„ë¡ íŠ¸ì—ì„œ íŒŒì‹± ê°€ëŠ¥)
    return {
        "reply": reply_text,
        "score": score,
        "level": level,
        "categories": categories,            # ex) ["GRAMMAR"] or []
        "grammar": g_txt,                    # ë¹ˆ ë¬¸ìì—´ ê°€ëŠ¥
        "vocabulary": v_txt,                 # ë¹ˆ ë¬¸ìì—´ ê°€ëŠ¥
        "suggestion": s_txt,                 # ë¹ˆ ë¬¸ìì—´ ê°€ëŠ¥
        # "voca": [{ "word": "prescription", "meaningKo": "...", "example": "..." }, ...]  # ìˆìœ¼ë©´ ì¶”ê°€
    }
